{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from enum import Enum\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora, models\n",
    "from gensim.models import Phrases\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定義 data types and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentType(Enum):\n",
    "    TIT = 'title'\n",
    "    ABS = 'abstract'\n",
    "    AUT = 'author'\n",
    "    SEC = 'section'\n",
    "    \n",
    "def get_contents(content_type):\n",
    "    all_contents = []\n",
    "    dataset_path = '../dataset'\n",
    "    for file in os.listdir(dataset_path):\n",
    "        file_path = os.path.join(dataset_path, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path) as f:  \n",
    "                line = f.readlines()\n",
    "                if content_type == ContentType.AUT:\n",
    "                    line = line[1]\n",
    "                elif content_type == ContentType.SEC:\n",
    "                    line = line[2]\n",
    "                elif content_type == ContentType.ABS:\n",
    "                    line = line[3]\n",
    "                else:\n",
    "                    line = line[0]\n",
    "                line = line.strip()\n",
    "                all_contents.append(line)\n",
    "        else:\n",
    "            print(file_path + ' does not exist.')\n",
    "    return all_contents\n",
    "\n",
    "\n",
    "def get_all_titles():\n",
    "    return get_contents(ContentType.TIT)\n",
    "\n",
    "def get_all_authors():        \n",
    "    return get_contents(ContentType.AUT)\n",
    "\n",
    "def get_all_sections():\n",
    "    return get_contents(ContentType.SEC)\n",
    "\n",
    "def get_all_abstracts():\n",
    "    return get_contents(ContentType.ABS)\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            token = wordnet_lemmatizer.lemmatize(token, pos='v')\n",
    "            token = wordnet_lemmatizer.lemmatize(token, pos='n')\n",
    "            result.append(token)\n",
    "    return result\n",
    "\n",
    "def get_chart_data(num_topics,num_words,topics):\n",
    "    buff = 300\n",
    "    K = num_topics\n",
    "    topicWordProbMat = topics\n",
    "    \n",
    "    #columns = ['1','2','3','4','5']\n",
    "    columns = range(1,num_topics+1)\n",
    "\n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    pd.set_option('display.width', 1000)\n",
    "\n",
    "    # 40 will be resized later to match number of words in DC\n",
    "    zz = np.zeros(shape=(buff,K))\n",
    "\n",
    "    last_number = 0\n",
    "    DC = {}\n",
    "\n",
    "    for x in range (num_words): #取每個topic前10個字\n",
    "        data= pd.DataFrame(columns=columns,index=[0])\n",
    "        for i in range(num_topics):\n",
    "            data[columns[i]] = \"\"\n",
    "        df = df.append(data,ignore_index=True)  \n",
    "\n",
    "    for line in topicWordProbMat:\n",
    "        topic_id,words = line #一個line是一個topic\n",
    "        probs = words.split(\"+\")\n",
    "        y = 0 #用來算第幾個word\n",
    "        for pr in probs:    \n",
    "            a = pr.split(\"*\")\n",
    "            df.iloc[y,topic_id] = a[1] #該word\n",
    "\n",
    "            if a[1] in DC:\n",
    "                zz[DC[a[1]]][topic_id] = a[0] #該word的機率\n",
    "            else:\n",
    "                zz[last_number][topic_id] = a[0]\n",
    "                DC[a[1]] = last_number\n",
    "                last_number = last_number+1\n",
    "            y = y + 1\n",
    "\n",
    "    return (df,DC,zz)\n",
    "\n",
    "def show_words_table(df):  \n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "def show_dictionary(DC):\n",
    "    print(DC)\n",
    "    print('字典字數：',len(DC))\n",
    "    print('\\n')\n",
    "\n",
    "def show_probs_table(zz):\n",
    "    print(zz)\n",
    "    print(zz.shape)\n",
    "    \n",
    "def show_heapmap(DC,zz):\n",
    "    %matplotlib inline\n",
    "\n",
    "    zz = np.resize(zz,(len(DC.keys()),zz.shape[1]))\n",
    "\n",
    "    for val, key in enumerate(DC.keys()):\n",
    "            plt.text(-3.5, val + 0.1, key,\n",
    "                     horizontalalignment='right',\n",
    "                     verticalalignment='center'\n",
    "                     )\n",
    "\n",
    "    #plt.figure(figsize=(10,50))\n",
    "    plt.imshow(zz, cmap='hot', interpolation='nearest',aspect=0.5)#'auto'\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 取出所有摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共 1343 篇論文\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>section</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Active Preference Learning Based on Generalize...</td>\n",
       "      <td>Nadjet Bourdache@Sorbonne University,Patrice P...</td>\n",
       "      <td>AAAI Technical Track: Reasoning under Uncertainty</td>\n",
       "      <td>We consider the problem of actively eliciting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generating Distractors for Reading Comprehensi...</td>\n",
       "      <td>Yifan Gao@The Chinese University of Hong Kong,...</td>\n",
       "      <td>AAAI Technical Track: Natural Language Processing</td>\n",
       "      <td>We investigate the task of distractor generati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acting and Planning Using Operational Models</td>\n",
       "      <td>Sunandita Patra@University of Maryland, Colleg...</td>\n",
       "      <td>AAAI Technical Track: Planning, Routing, and S...</td>\n",
       "      <td>The most common representation formalisms for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lifted Hinge-Loss Markov Random Fields</td>\n",
       "      <td>Sriram Srinivasan@University of California, Sa...</td>\n",
       "      <td>AAAI Technical Track: Reasoning under Uncertainty</td>\n",
       "      <td>Statistical relational learning models are pow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLOCK: Bilinear Superdiagonal Fusion for Visua...</td>\n",
       "      <td>Hedi Ben-younes@Sorbonne Université,Remi Caden...</td>\n",
       "      <td>AAAI Technical Track: Vision</td>\n",
       "      <td>Multimodal representation learning is gaining ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Meta Learning for Image Captioning</td>\n",
       "      <td>Nannan Li@Wuhan University,Zhenzhong Chen@Wuha...</td>\n",
       "      <td>AAAI Technical Track: Vision</td>\n",
       "      <td>Reinforcement learning (RL) has shown its adva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Personalized Robot Tutoring Using the Assistiv...</td>\n",
       "      <td>Aditi Ramachandran@Yale University,Sarah Stroh...</td>\n",
       "      <td>AAAI Technical Track: Robotics</td>\n",
       "      <td>Selecting appropriate tutoring help actions th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Pattern-Based Approach to Recognizing Time E...</td>\n",
       "      <td>Wentao Ding@Nanjing University,Guanji Gao@Nanj...</td>\n",
       "      <td>AAAI Technical Track: Natural Language Processing</td>\n",
       "      <td>Recognizing time expressions is a fundamental ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Towards Optimal Discrete Online Hashing with B...</td>\n",
       "      <td>Mingbao Lin@Xiamen University,Rongrong Ji@Xiam...</td>\n",
       "      <td>AAAI Technical Track: Vision</td>\n",
       "      <td>When facing large-scale image datasets, online...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Temporal Bilinear Networks for Video Action Re...</td>\n",
       "      <td>Yanghao Li@Peking University,Sijie Song@Peking...</td>\n",
       "      <td>AAAI Technical Track: Vision</td>\n",
       "      <td>Temporal modeling in videos is a fundamental y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Active Preference Learning Based on Generalize...   \n",
       "1  Generating Distractors for Reading Comprehensi...   \n",
       "2       Acting and Planning Using Operational Models   \n",
       "3             Lifted Hinge-Loss Markov Random Fields   \n",
       "4  BLOCK: Bilinear Superdiagonal Fusion for Visua...   \n",
       "5                 Meta Learning for Image Captioning   \n",
       "6  Personalized Robot Tutoring Using the Assistiv...   \n",
       "7  A Pattern-Based Approach to Recognizing Time E...   \n",
       "8  Towards Optimal Discrete Online Hashing with B...   \n",
       "9  Temporal Bilinear Networks for Video Action Re...   \n",
       "\n",
       "                                              author  \\\n",
       "0  Nadjet Bourdache@Sorbonne University,Patrice P...   \n",
       "1  Yifan Gao@The Chinese University of Hong Kong,...   \n",
       "2  Sunandita Patra@University of Maryland, Colleg...   \n",
       "3  Sriram Srinivasan@University of California, Sa...   \n",
       "4  Hedi Ben-younes@Sorbonne Université,Remi Caden...   \n",
       "5  Nannan Li@Wuhan University,Zhenzhong Chen@Wuha...   \n",
       "6  Aditi Ramachandran@Yale University,Sarah Stroh...   \n",
       "7  Wentao Ding@Nanjing University,Guanji Gao@Nanj...   \n",
       "8  Mingbao Lin@Xiamen University,Rongrong Ji@Xiam...   \n",
       "9  Yanghao Li@Peking University,Sijie Song@Peking...   \n",
       "\n",
       "                                             section  \\\n",
       "0  AAAI Technical Track: Reasoning under Uncertainty   \n",
       "1  AAAI Technical Track: Natural Language Processing   \n",
       "2  AAAI Technical Track: Planning, Routing, and S...   \n",
       "3  AAAI Technical Track: Reasoning under Uncertainty   \n",
       "4                       AAAI Technical Track: Vision   \n",
       "5                       AAAI Technical Track: Vision   \n",
       "6                     AAAI Technical Track: Robotics   \n",
       "7  AAAI Technical Track: Natural Language Processing   \n",
       "8                       AAAI Technical Track: Vision   \n",
       "9                       AAAI Technical Track: Vision   \n",
       "\n",
       "                                            abstract  \n",
       "0  We consider the problem of actively eliciting ...  \n",
       "1  We investigate the task of distractor generati...  \n",
       "2  The most common representation formalisms for ...  \n",
       "3  Statistical relational learning models are pow...  \n",
       "4  Multimodal representation learning is gaining ...  \n",
       "5  Reinforcement learning (RL) has shown its adva...  \n",
       "6  Selecting appropriate tutoring help actions th...  \n",
       "7  Recognizing time expressions is a fundamental ...  \n",
       "8  When facing large-scale image datasets, online...  \n",
       "9  Temporal modeling in videos is a fundamental y...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = get_all_titles()\n",
    "sections = get_all_sections()\n",
    "authors = get_all_authors()\n",
    "contents = get_all_abstracts()\n",
    "\n",
    "print('共',len(contents),'篇論文\\n')\n",
    "\n",
    "documents = pd.DataFrame(columns=['title','author','section','abstract'])\n",
    "#documents = pd.DataFrame(data=contents,columns=['abstract'])\n",
    "#documents['index'] = documents.index\n",
    "documents['title'] = titles\n",
    "documents['author'] = authors\n",
    "documents['section'] = sections\n",
    "documents['abstract'] = contents\n",
    "documents[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 預處理的全部論文摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [consider, problem, actively, elicit, preferen...\n",
       "1    [investigate, task, distractor, generation, mu...\n",
       "2    [common, representation, formalism, plan, desc...\n",
       "3    [statistical, relational, learn, model, powerf...\n",
       "4    [multimodal, representation, learn, gain, deep...\n",
       "5    [reinforcement, learn, show, advantage, image,...\n",
       "6    [select, appropriate, tutor, help, action, acc...\n",
       "7    [recognize, time, expression, fundamental, imp...\n",
       "8    [face, large, scale, image, datasets, online, ...\n",
       "9    [temporal, model, video, fundamental, challeng...\n",
       "Name: abstract, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = documents['abstract'].map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### 產生字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共 6927 個字\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "print('共',len(dictionary),'個字\\n')\n",
    "\n",
    "# Filter out words that occur less than 10 documents, or more than 20% of the documents.\n",
    "#dictionary.filter_extremes(no_below=10, no_above=0.2)\n",
    "#print('Number of unique words after removing rare and common words:', len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 產生 bag of words corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "print('共',len(bow_corpus),'筆')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LDA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 10\n",
    "num_words = 10\n",
    "passes = 30\n",
    "iterations = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LDA using BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                       num_topics=num_topics, \n",
    "                                       id2word=dictionary, \n",
    "                                       passes=passes,\n",
    "                                       iterations=iterations,\n",
    "                                       eval_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary)\n",
    "# 在 notebook 中显示可视化结果，需要调用 display 方法，或者执行 “pyLDAvis.enable_notebook()” ，即可在 notebook 中自动展示可视化结果，无需再调用 display\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../models/lda_unigram_bow_filtered_topic_'+ str(num_topics) +'.model'\n",
    "print(file_name)\n",
    "lda_model.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
