Connecting the Digital and Physical World: Improving the Robustness of Adversarial Attacks
Steve T.K. Jan@Virginia Polytechnic Institute and State University,Joseph Messou@Virginia Polytechnic Institute and State University,Yen-Chen Lin@National Tsing Hua University,Jia-Bin Huang@Virginia Polytechnic Institute and State University,Gang Wang@Virginia Polytechnic Institute and State University
AAAI Technical Track: Applications
While deep learning models have achieved unprecedented success in various domains, there is also a growing concern of adversarial attacks against related applications. Recent results show that by adding a small amount of perturbations to an image (imperceptible to humans), the resulting adversarial examples can force a classifier to make targeted mistakes. So far, most existing works focus on crafting adversarial examples in the digital domain, while limited efforts have been devoted to understanding the physical domain attacks. In this work, we explore the feasibility of generating robust adversarial examples that remain effective in the physical domain. Our core idea is to use an image-to-image translation network to simulate the digital-to-physical transformation process for generating robust adversarial examples. To validate our method, we conduct a large-scale physical-domain experiment, which involves manually taking more than 3000 physical domain photos. The results show that our method outperforms existing ones by a large margin and demonstrates a high level of robustness and transferability.
